{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAkFBgd-eDgb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "entries = os.listdir('./Camera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rwV5HPDZe8ta",
    "outputId": "59ec3ecf-fea2-4ea4-cff2-7e1db1cd4959"
   },
   "outputs": [],
   "source": [
    "\n",
    "path='./Camera/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIhlaE9meDg5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "class Img2Vec():\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet-18', layer='default', layer_output_size=512):\n",
    "        \"\"\" Img2Vec\n",
    "        :param cuda: If set to True, will run forward pass on GPU\n",
    "        :param model: String name of requested model\n",
    "        :param layer: String or Int depending on model.  See more docs: https://github.com/christiansafka/img2vec.git\n",
    "        :param layer_output_size: Int depicting the output size of the requested layer\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "        \n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Scale((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        \"\"\" Get vector embedding from PIL image\n",
    "        :param img: PIL Image or list of PIL Images\n",
    "        :param tensor: If True, get_vec will return a FloatTensor instead of Numpy array\n",
    "        :returns: Numpy ndarray\n",
    "        \"\"\"\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device) \n",
    "            if self.model_name == 'alexnet':\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name == 'alexnet':\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                else:\n",
    "                    print(my_embedding.numpy()[:, :, 0, 0].shape)\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name == 'alexnet':\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name == 'alexnet':\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        \"\"\" Internal method for getting layer from model\n",
    "        :param model_name: model name such as 'resnet-18'\n",
    "        :param layer: layer as a string for resnet-18 or int for alexnet\n",
    "        :returns: pytorch model, selected layer\n",
    "        \"\"\"\n",
    "        if model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "k8Hk8VUteDg-",
    "outputId": "d6059bd4-faea-4d5c-b42f-6ba810a1f312"
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import os\n",
    "\n",
    "input_path=path\n",
    "entries = os.listdir('./Camera')\n",
    "# entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477,
     "referenced_widgets": [
      "5f1ef02805ef4c64859324d59e5b63fa",
      "020bdd9315e04cf08cae998002531e2a",
      "365d68e42e3847318fc961a7f2590a5d",
      "f10b6fab4d3b4d2f89629a7884616b6a",
      "e543608437a34034b8cbc697a9502f30",
      "be92830749304af79d91ed5d27da7a1f",
      "2ae74ef2749747cb8cf42bf0681d0fbe",
      "dae0b66c64804205b406eb961288fd7b"
     ]
    },
    "colab_type": "code",
    "id": "CjHpdw98eDhE",
    "outputId": "1f621692-90a8-4384-ab82-760002cbcfa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot identify image file './Camera\\\\VID_20160827_071713.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b0d13c706464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Camera'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfsdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Camera'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\test_env\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2816\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccept_warnings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2817\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2818\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot identify image file %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: cannot identify image file './Camera\\\\VID_20160827_071713.mp4'"
     ]
    }
   ],
   "source": [
    "img2vec = Img2Vec()\n",
    "from PIL import Image\n",
    "# For each test image, we store the filename and vector as key, value in a dictionary\n",
    "pics = {}\n",
    "i=0\n",
    "for file in os.listdir('./Camera'):\n",
    "    filename = os.fsdecode(file)\n",
    "    img = Image.open(os.path.join('./Camera', filename))\n",
    "    vec = img2vec.get_vec(img)\n",
    "    pics[filename] = vec    \n",
    "    i=i+1\n",
    "    if(i%200==0):\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3506"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Kxfc0Os1QGW"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"My_rotation_matrix.bin\", \"wb\") as output:\n",
    "    pickle.dump(pics, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "liIuSl8C1e8I"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"My_rotation_matrix.bin\", \"rb\") as data:\n",
    "    pics = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uZ3ibvsfeZo"
   },
   "outputs": [],
   "source": [
    "vector_key=[]\n",
    "for key in pics:\n",
    "  # print(key,pics[key])\n",
    "  vector_key+=[pics[key]]\n",
    "  # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ii3Z-8ewl6BT",
    "outputId": "fb18dc5b-52da-4842-cc76-c24822483cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3506"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "_1Exq1m5eDh2",
    "outputId": "031d34d5-9f26-4e20-bc9a-176778e85f7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters=5\n",
    "from sklearn.cluster import KMeans\n",
    "Kmean = KMeans(n_clusters=5)\n",
    "Kmean.fit(vector_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_xiabrYxeDh7",
    "outputId": "bcace865-a6a6-4775-feec-0e3dcc54c113"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 1, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kmean.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "XnBobai3eDiC",
    "outputId": "edad1cd2-2286-425d-c7c8-36036ad1be4d"
   },
   "outputs": [],
   "source": [
    "n_clusters=5 \n",
    "\n",
    "# Python program to explain os.mkdir() method \n",
    "  \n",
    "# importing os module \n",
    "import os \n",
    "  \n",
    "# Directory \n",
    "# directory = \"1\"\n",
    "  \n",
    "# Parent Directory path \n",
    "\n",
    "# os.mkdir(path)   \n",
    "# Path \n",
    "for i in range(0,5):\n",
    "    path='./Camera'\n",
    "    path = os.path.join(path, str(i)) \n",
    "    os.mkdir(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "unk0uQbrns2n",
    "outputId": "2f063830-e41e-497b-f721-305f4dcfa430"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Kmean.labels_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HUmhzVXyo97U",
    "outputId": "582afef6-fabd-48a6-9fc8-e17c3fd5b65e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3506 3506\n"
     ]
    }
   ],
   "source": [
    "i=0;\n",
    "count=0;\n",
    "for key in pics:\n",
    "    if((pics[key]==vector_key[i]).all()):\n",
    "        count+=1;\n",
    "    i+=1;\n",
    "print(i,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Vnz1yjPeDiK"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "i=0;\n",
    "count=0;\n",
    "for key in pics:\n",
    "    path='./Camera/'\n",
    "    path = path+'/'+str(Kmean.labels_[i])\n",
    "    img = Image.open(os.path.join('./Camera/', key))\n",
    "    img = img.save(path+'/'+key) \n",
    "    i+=1;\n",
    "# print(i,count)for i in range(0,len(Kmean.labels_)):\n",
    "#     path = os.path.join(path, str(Kmean.labels_[i])) \n",
    "#     # os.mkdir(path) \n",
    "#     im1 = im1.save(path+) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3506"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "seperate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "020bdd9315e04cf08cae998002531e2a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ae74ef2749747cb8cf42bf0681d0fbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "365d68e42e3847318fc961a7f2590a5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be92830749304af79d91ed5d27da7a1f",
      "max": 46827520,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e543608437a34034b8cbc697a9502f30",
      "value": 46827520
     }
    },
    "5f1ef02805ef4c64859324d59e5b63fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_365d68e42e3847318fc961a7f2590a5d",
       "IPY_MODEL_f10b6fab4d3b4d2f89629a7884616b6a"
      ],
      "layout": "IPY_MODEL_020bdd9315e04cf08cae998002531e2a"
     }
    },
    "be92830749304af79d91ed5d27da7a1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dae0b66c64804205b406eb961288fd7b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e543608437a34034b8cbc697a9502f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f10b6fab4d3b4d2f89629a7884616b6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dae0b66c64804205b406eb961288fd7b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2ae74ef2749747cb8cf42bf0681d0fbe",
      "value": "100% 44.7M/44.7M [00:00&lt;00:00, 191MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
